<!DOCTYPE html>




<html class="theme-next muse" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png?v=5.1.4">






  <meta name="keywords" content="Machine Learning, Data Science, Anime, Otaku, CMU, Google, Knowledge Sharing" />





  <link rel="alternate" href="/atom.xml" title="Wille" type="application/atom+xml" />






<meta name="description" content="IntroductionKaggle is the best place to learn from other data scientists. Many companies provide data and prize money to set up data science competitions on Kaggle. Recently I had my first shot on Kag">
<meta name="keywords" content="Machine Learning, Data Science, Anime, Otaku, CMU, Google, Knowledge Sharing">
<meta property="og:type" content="article">
<meta property="og:title" content="How to Rank 10% in Your First Kaggle Competition">
<meta property="og:url" content="http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/index.html">
<meta property="og:site_name" content="Wille">
<meta property="og:description" content="IntroductionKaggle is the best place to learn from other data scientists. Many companies provide data and prize money to set up data science competitions on Kaggle. Recently I had my first shot on Kag">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/kaggle-guide-profile.png">
<meta property="og:image" content="http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/kaggle-guide-outlier-example.png">
<meta property="og:image" content="http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/kaggle-guide-dummies-example.png">
<meta property="og:image" content="http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/kaggle-visualize-feature-correlation.png">
<meta property="og:image" content="http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/kaggle-guide-stacking-diagram.jpg">
<meta property="og:updated_time" content="2019-01-19T04:05:07.860Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="How to Rank 10% in Your First Kaggle Competition">
<meta name="twitter:description" content="IntroductionKaggle is the best place to learn from other data scientists. Many companies provide data and prize money to set up data science competitions on Kaggle. Recently I had my first shot on Kag">
<meta name="twitter:image" content="http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/kaggle-guide-profile.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/"/>





  <title>How to Rank 10% in Your First Kaggle Competition | Wille</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-121702790-1', 'auto');
  ga('send', 'pageview');
</script>





</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Wille</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">最後に辿り着いた場所</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Linghao Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/asuka.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wille">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">How to Rank 10% in Your First Kaggle Competition</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-05-10T23:06:51-07:00">
                2016-05-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Data-Science/" itemprop="url" rel="index">
                    <span itemprop="name">Data Science</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2016/05/rank-10-percent-in-first-kaggle-competition-en/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2016/05/rank-10-percent-in-first-kaggle-competition-en/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              

              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  30
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><a href="https://www.kaggle.com/" target="_blank" rel="noopener">Kaggle</a> is the best place to learn from other data scientists. Many companies provide data and prize money to set up data science competitions on Kaggle. Recently I had my first shot on Kaggle and <strong>ranked 98th (~ 5%) among 2125 teams</strong>. Being my Kaggle debut, I feel quite satisfied with the result. Since many Kaggle beginners set 10% as their first goal, I want to share my two cents on how to achieve that.</p>
<p><em>This post is also available in <a href="https://dnc1994.com/2016/04/rank-10-percent-in-first-kaggle-competition/">Chinese</a>.</em></p>
<p><strong>Updated on Oct 28th, 2016: </strong> I made many wording changes and added several updates to this post. Note that Kaggle has went through some major changes since I published this post, especially with its ranking system. Therefore some descriptions here might not apply anymore.</p>
<a id="more"></a>
<p><img src="kaggle-guide-profile.png" alt="Kaggle Profile"></p>
<p>Most Kagglers use Python or R. I prefer Python, but R users should have no difficulty in understanding the ideas behind tools and languages.</p>
<p>First let’s go through some facts about Kaggle competitions in case you are not familiar with them.</p>
<ul>
<li><p>Different competitions have different tasks: classifications, regressions, recommendations… Training set and testing set will be open for download after the competition launches.</p>
</li>
<li><p>A competition typically lasts for 2 ~ 3 months. Each team can submit for a limited number of times per day. Usually it’s 5 times a day.</p>
</li>
<li><p>There will be a 1st submission deadline one week before the end of the competition, after which you cannot merge teams or enter the competition. Therefore <strong>be sure to have at least one valid submission before that.</strong></p>
</li>
<li><p>You will get you score immediately after the submission. Different competitions use different scoring metrics, which are explained by the question mark on the leaderboard.</p>
</li>
<li><p>The score you get is calculated on a subset of testing set, which is commonly referred to as a <strong>Public LB</strong> score. Whereas the final result will use the remaining data in the testing set, which is referred to as a <strong>Private LB</strong> score.</p>
</li>
<li><p>The score you get by local cross validation is commonly referred to as a <strong>CV</strong> score. Generally speaking, CV scores are more reliable than LB scores.</p>
</li>
<li><p>Beginners can learn a lot from <strong>Forum</strong> and <strong>Scripts</strong>. Do not hesitate to ask about anything. Kagglers are in general very kind and helpful.</p>
</li>
</ul>
<p>I assume that readers are familiar with basic concepts and models of machine learning. Enjoy reading!</p>
<h2 id="General-Approach"><a href="#General-Approach" class="headerlink" title="General Approach"></a>General Approach</h2><p>In this section, I will walk you through the process of a Kaggle competition.</p>
<h3 id="Data-Exploration"><a href="#Data-Exploration" class="headerlink" title="Data Exploration"></a>Data Exploration</h3><p>What we do at this stage is called <strong>EDA (Exploratory Data Analysis)</strong>, which means analytically exploring data in order to provide some insights for subsequent processing and modeling.</p>
<p>Usually we would load the data using <strong><a href="http://pandas.pydata.org/" target="_blank" rel="noopener">Pandas</a></strong> and make some visualizations to understand the data.</p>
<h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p>For plotting, <strong><a href="http://matplotlib.org/" target="_blank" rel="noopener">Matplotlib</a></strong> and <strong><a href="https://stanford.edu/~mwaskom/software/seaborn/" target="_blank" rel="noopener">Seaborn</a></strong> should suffice.</p>
<p>Some common practices:</p>
<ul>
<li>Inspect the distribution of target variable. Depending on what scoring metric is used, <strong>an <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5128907" target="_blank" rel="noopener">imbalanced</a> distribution of target variable might harm the model’s performance</strong>.</li>
<li>For <strong>numerical variables</strong>, use <strong>box plot</strong> and <strong>scatter plot</strong> to inspect their distributions and check for outliers.</li>
<li>For classification tasks, plot the data with points colored according to their labels. This can help with feature engineering.</li>
<li>Make pairwise distribution plots and examine their correlations.</li>
</ul>
<p>Be sure to read <a href="https://www.kaggle.com/benhamner/d/uciml/iris/python-data-visualizations" target="_blank" rel="noopener">this inspiring tutorial of exploratory visualization</a> before you go on.</p>
<h4 id="Statistical-Tests"><a href="#Statistical-Tests" class="headerlink" title="Statistical Tests"></a>Statistical Tests</h4><p>We can perform some statistical tests to confirm our hypotheses. Sometimes we can get enough intuition from visualization, but quantitative results are always good to have. Note that we will always encounter non-i.i.d. data in real world. So we have to be careful about which test to use and how we interpret the findings.</p>
<p>In many competitions public LB scores are not very consistent with local CV scores due to noise or non-i.i.d. distribution. You can use test results to <strong>roughly set a threshold for determining whether an increase of score is due to genuine improvment or randomness</strong>.</p>
<h3 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h3><p>In most cases, we need to preprocess the dataset before constructing features. Some common steps are:</p>
<ul>
<li>Sometimes several files are provided and we need to join them.</li>
<li>Deal with <strong><a href="https://en.wikipedia.org/wiki/Missing_data" target="_blank" rel="noopener">missing data</a></strong>.</li>
<li>Deal with <strong><a href="https://en.wikipedia.org/wiki/Outlier" target="_blank" rel="noopener">outliers</a></strong>.</li>
<li>Encode <strong><a href="https://en.wikipedia.org/wiki/Categorical_variable" target="_blank" rel="noopener">categorical variables</a></strong> if necessary.</li>
<li>Deal with noise. For example you may have some floats derived from raw figures. The loss of precision during floating-point arithemics can bring much noise into the data: two seemingly different values might be the same before conversion. Sometimes noise harms model and we would want to avoid that.</li>
</ul>
<p>How we choose to perform preprocessing largely depends on what we learn about the data in the previous stage. In practice, I recommend using <strong><a href="http://ipython.org/notebook.html" target="_blank" rel="noopener">Jupyter Notebook</a></strong> for data manipulation and mastering usage of frequently used Pandas operations. The advantage is that you get to see the results immediately and are able to modify or rerun code blocks. This also makes it very convenient to share your approach with others. After all <a href="https://en.wikipedia.org/wiki/Reproducibility" target="_blank" rel="noopener">reproducible results</a> are very important in data science.</p>
<p>Let’s see some examples.</p>
<h4 id="Outlier"><a href="#Outlier" class="headerlink" title="Outlier"></a>Outlier</h4><p><img src="kaggle-guide-outlier-example.png" alt="Outlier Example"></p>
<p>The plot shows some scaled coordinates data. We can see that there are some outliers in the top-right corner. Exclude them and the distribution looks good.</p>
<h4 id="Dummy-Variables"><a href="#Dummy-Variables" class="headerlink" title="Dummy Variables"></a>Dummy Variables</h4><p>For categorical variables, a common practice is <strong><a href="https://en.wikipedia.org/wiki/One-hot" target="_blank" rel="noopener">One-hot Encoding</a></strong>. For a categorical variable with <code>n</code> possible values, we create a group of <code>n</code> dummy variables. Suppose a record in the data takes one value for this variable, then the corresponding dummy variable is set to <code>1</code> while other dummies in the same group are all set to <code>0</code>.</p>
<p><img src="kaggle-guide-dummies-example.png" alt="Dummies Example"></p>
<p>In this example, we transform <code>DayOfWeek</code> into 7 dummy variables.</p>
<p>Note that when the categorical variable can take many values (hundreds or more), this might not work well. It’s difficult to find a general solution to that, but I’ll discuss one scenario in the next section.</p>
<h3 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h3><p>Some describe the essence of Kaggle competitions as <strong>feature engineering supplemented by model tuning and ensemble learning</strong>. Yes, that makes a lot of sense. <strong>Feature engineering gets your very far.</strong> Yet it is how well you know about the domain of given data that decides how far you can go. For example, in a competition where data is mainly consisted of texts, Natural Language Processing teachniques are a must. The approach of constructing useful features is something we all have to continuously learn in order to do better.</p>
<p>Basically, <strong>when you feel that a variable is intuitively useful for the task, you can include it as a feature</strong>. But how do you know it actually works? The simplest way is to plot it against the target variable like this:</p>
<p><img src="kaggle-visualize-feature-correlation.png" alt="Checking Feature Validity"></p>
<h4 id="Feature-Selection"><a href="#Feature-Selection" class="headerlink" title="Feature Selection"></a>Feature Selection</h4><p>Generally speaking, <strong>we should try to craft as many features as we can and have faith in the model’s ability to pick up the most significant features</strong>. Yet there’s still something to gain from feature selection beforehand:</p>
<ul>
<li>Less features mean faster training</li>
<li>Some features are linearly related to others. This might put a strain on the model.</li>
<li>By picking up the most important features, we can use interactions between them as new features. Sometimes this gives surprising improvement.</li>
</ul>
<p>The simplest way to inspect feature importance is by fitting a random forest model. There are more robust feature selection algorithms (e.g. <a href="http://jmlr.org/papers/volume10/tuv09a/tuv09a.pdf" target="_blank" rel="noopener">this</a>) which are theoretically superior but not practicable due to the absence of efficient implementation. You can combat noisy data (to an extent) simply by increasing number of trees used in a random forest.</p>
<p>This is important for competitions in which data is <strong><a href="https://en.wikipedia.org/wiki/Data_anonymization" target="_blank" rel="noopener">anonymized</a></strong> because you won’t waste time trying to figure out the meaning of a variable that’s of no significance.</p>
<h4 id="Feature-Encoding"><a href="#Feature-Encoding" class="headerlink" title="Feature Encoding"></a>Feature Encoding</h4><p>Sometimes raw features have to be converted to some other formats for them to work properly.</p>
<p>For example, suppose we have a categorical variable which can take more than 10K different values. Then naively creating dummy variables is not a feasible option. An acceptable solution is to create dummy variables for only a subset of the values (e.g. values that constitute 95% of the feature importance) and assign everything else to an ‘others’ class.</p>
<p><strong>Updated on Oct 28th, 2016: </strong> For the scenario described above, another possible solution is to use <strong>Factorized Machines</strong>. Please refer to <a href="https://www.kaggle.com/c/expedia-hotel-recommendations/forums/t/21607/1st-place-solution-summary" target="_blank" rel="noopener">this post</a> by Kaggle user “idle_speculation” for details.</p>
<h3 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h3><p>When the features are set, we can start training models. Kaggle competitions usually favor <strong>tree-based models</strong>:</p>
<ul>
<li><strong>Gradient Boosted Trees</strong></li>
<li>Random Forest</li>
<li>Extra Randomized Trees</li>
</ul>
<p>The following models are slightly worse in terms of general performance, but are suitable as base models in ensemble learning (will be discussed later):</p>
<ul>
<li>SVM</li>
<li>Linear Regression</li>
<li>Logistic Regression</li>
<li>Neural Networks</li>
</ul>
<p>Note that this does not apply to computer vision competitions which are pretty much dominated by neural network models.</p>
<p>All these models are implemented in <strong><a href="http://scikit-learn.org/" target="_blank" rel="noopener">Sklearn</a></strong>.</p>
<p>Here I want to emphasize the greatness of <strong><a href="https://github.com/dmlc/xgboost" target="_blank" rel="noopener">Xgboost</a></strong>. The outstanding performance of gradient boosted trees and Xgboost’s efficient implementation makes it very popular in Kaggle competitions. Nowadays almost every winner uses Xgboost in one way or another.</p>
<p><strong>Updated on Oct 28th, 2016: </strong> Recently Microsoft open sourced <strong><a href="https://github.com/Microsoft/LightGBM" target="_blank" rel="noopener">LightGBM</a></strong>, a potentially better library than Xgboost for gradient boosting.</p>
<p>By the way, for Windows users installing Xgboost could be a painstaking process. You can refer to <a href="https://dnc1994.com/2016/03/installing-xgboost-on-windows/">this post</a> by me if you run into problems.</p>
<h4 id="Model-Training"><a href="#Model-Training" class="headerlink" title="Model Training"></a>Model Training</h4><p>We can improve a model’s performance by tuning its parameters. A model usually have many parameters, but only a few of them are significant to its performance. For example, the most important parameters for a random forset is the number of trees in the forest and the maximum number of features used in developing each tree. <strong>We need to understand how models work and what impact does each parameter have to the model’s performance, be it accuracy, robustness or speed.</strong></p>
<p>Normally we would find the best set of parameters by a process called <strong><a href="http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html)" target="_blank" rel="noopener">grid search</a></strong>. Actually what it does is simply iterating through all the possible combinations and find the best one.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">param_grid = &#123;<span class="string">'n_estimators'</span>: [<span class="number">300</span>, <span class="number">500</span>], <span class="string">'max_features'</span>: [<span class="number">10</span>, <span class="number">12</span>, <span class="number">14</span>]&#125;</span><br><span class="line">model = grid_search.GridSearchCV(</span><br><span class="line">    estimator=rfr, param_grid=param_grid, n_jobs=<span class="number">1</span>, cv=<span class="number">10</span>, verbose=<span class="number">20</span>, scoring=RMSE</span><br><span class="line">)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p>By the way, random forest usually reach optimum when <code>max_features</code> is set to the square root of the total number of features.</p>
<p>Here I’d like to stress some points about tuning XGB. These parameters are generally considered to have real impacts on its performance:</p>
<ul>
<li><code>eta</code>: Step size used in updating weights. Lower <code>eta</code> means slower training but better convergence.</li>
<li><code>num_round</code>: Total number of iterations.</li>
<li><code>subsample</code>: The ratio of training data used in each iteration. This is to combat overfitting.</li>
<li><code>colsample_bytree</code>: The ratio of features used in each iteration. This is like <code>max_features</code> in <code>RandomForestClassifier</code>.</li>
<li><code>max_depth</code>: The maximum depth of each tree. Unlike random forest, <strong>gradient boosting would eventually overfit if we do not limit its depth</strong>.</li>
<li><code>early_stopping_rounds</code>: If we don’t see an increase of validation score for a given number of iterations, the algorithm will stop early. This is to combat overfitting, too.</li>
</ul>
<p>Usual tuning steps:</p>
<ol>
<li>Reserve a portion of training set as the validation set.</li>
<li>Set <code>eta</code> to a relatively high value (e.g. 0.05 ~ 0.1), <code>num_round</code> to 300 ~ 500.</li>
<li>Use grid search to find the best combination of other parameters.</li>
<li>Gradually lower <code>eta</code> until we reach the optimum.</li>
<li><strong>Use the validation set as <code>watch_list</code> to re-train the model with the best parameters. Observe how score changes on validation set in each iteration. Find the optimal value for <code>early_stopping_rounds</code>.</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">X_dtrain, X_deval, y_dtrain, y_deval = \</span><br><span class="line">    cross_validation.train_test_split(X_train, y_train, random_state=<span class="number">1026</span>, test_size=<span class="number">0.3</span>)</span><br><span class="line">dtrain = xgb.DMatrix(X_dtrain, y_dtrain)</span><br><span class="line">deval = xgb.DMatrix(X_deval, y_deval)</span><br><span class="line">watchlist = [(deval, <span class="string">'eval'</span>)]</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'booster'</span>: <span class="string">'gbtree'</span>,</span><br><span class="line">    <span class="string">'objective'</span>: <span class="string">'reg:linear'</span>,</span><br><span class="line">    <span class="string">'subsample'</span>: <span class="number">0.8</span>,</span><br><span class="line">    <span class="string">'colsample_bytree'</span>: <span class="number">0.85</span>,</span><br><span class="line">    <span class="string">'eta'</span>: <span class="number">0.05</span>,</span><br><span class="line">    <span class="string">'max_depth'</span>: <span class="number">7</span>,</span><br><span class="line">    <span class="string">'seed'</span>: <span class="number">2016</span>,</span><br><span class="line">    <span class="string">'silent'</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">'eval_metric'</span>: <span class="string">'rmse'</span></span><br><span class="line">&#125;</span><br><span class="line">clf = xgb.train(params, dtrain, <span class="number">500</span>, watchlist, early_stopping_rounds=<span class="number">50</span>)</span><br><span class="line">pred = clf.predict(xgb.DMatrix(df_test))</span><br></pre></td></tr></table></figure>
<p>Finally, note that models with randomness all have a parameter like <code>seed</code> or <code>random_state</code> to control the random seed. <strong>You must record this</strong> with all other parameters when you get a good model. Otherwise you wouldn’t be able to reproduce it.</p>
<h4 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h4><p><strong><a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" target="_blank" rel="noopener">Cross validation</a></strong> is an essential step in model training. It tells us whether our model is at high risk of overfitting. In many competitions, public LB scores are not very reliable. Often when we improve the model and get a better local CV score, the LB score becomes worse. <strong>It is widely believed that we should trust our CV scores under such situation.</strong> Ideally we would want <strong>CV scores obtained by different approaches to improve in sync with each other and with the LB score</strong>, but this is not always possible.</p>
<p>Usually <strong>5-fold CV</strong> is good enough. If we use more folds, the CV score would become more reliable, but the training takes longer to finish as well. However, we shouldn’t use too many folds if our training data is limited. Otherwise we would have too few samples in each fold to guarantee statistical significance.</p>
<p>How to do CV properly is not a trivial problem. It requires constant experiment and case-by-case discussion. Many Kagglers share their CV approaches (like <a href="https://www.kaggle.com/c/telstra-recruiting-network/forums/t/19277/what-is-your-cross-validation-method" target="_blank" rel="noopener">this one</a>) after competitions when they feel that reliable CV is not easy.</p>
<h3 id="Ensemble-Generation"><a href="#Ensemble-Generation" class="headerlink" title="Ensemble Generation"></a>Ensemble Generation</h3><p><a href="https://en.wikipedia.org/wiki/Ensemble_learning" target="_blank" rel="noopener">Ensemble Learning</a> refers to the technique of combining different models. It <strong>reduces both bias and variance of the final model</strong> (you can find a proof <a href="http://link.springer.com/chapter/10.1007%2F3-540-33019-4_19" target="_blank" rel="noopener">here</a>), thus <strong>increasing the score and reducing the risk of overfitting</strong>. Recently it became virtually impossible to win prize without using ensemble in Kaggle competitions.</p>
<p>Common approaches of ensemble learning are:</p>
<ul>
<li><p><strong>Bagging</strong>: Use different random subsets of training data to train each base model. Then all the base models vote to generate the final predictions. This is how random forest works.</p>
</li>
<li><p><strong>Boosting</strong>: Train base models iteratively, modify the weights of training samples according to the last iteration. This is how gradient boosted trees work. (Actually it’s not the whole story. Apart from boosting, GBTs try to learn the residuals of earlier iterations.) It performs better than bagging but is more prone to overfitting.</p>
</li>
<li><p><strong>Blending</strong>: Use non-overlapping data to train different base models and take a weighted average of them to obtain the final predictions. This is easy to implement but uses less data.</p>
</li>
<li><p><strong>Stacking</strong>: To be discussed next.</p>
</li>
</ul>
<p>In theory, for the ensemble to perform well, two factors matter:</p>
<ul>
<li><strong>Base models should be as unrelated as possibly</strong>. This is why we tend to include non-tree-based models in the ensemble even though they don’t perform as well. The math says that the greater the diversity, and less bias in the final ensemble.</li>
<li><strong>Performance of base models shouldn’t differ to much.</strong></li>
</ul>
<p>Actually we have a <strong>trade-off</strong> here. In practice we may end up with highly related models of comparable performances. Yet we ensemble them anyway because it usually increase the overall performance.</p>
<h4 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h4><p>Compared with blending, stacking makes better use of training data. Here’s a diagram of how it works:</p>
<p><img src="kaggle-guide-stacking-diagram.jpg" alt="Stacking"></p>
<p><em>(Taken from <a href="https://www.kaggle.com/mmueller" target="_blank" rel="noopener">Faron</a>. Many thanks!)</em></p>
<p>It’s much like cross validation. Take 5-fold stacking as an example. First we split the training data into 5 folds. Next we will do 5 iterations. In each iteration, train every base model on 4 folds and predict on the hold-out fold. <strong>You have to keep the predictions on the testing data as well.</strong> This way, in each iteration every base model will make predictions on 1 fold of the training data and all of the testing data. After 5 iterations we will obtain a matrix of shape <code>#(samples in training data) X #(base models)</code>. This matrix is then fed to the stacker (it’s just another model) in the second level. After the stacker is fitted, use the predictions on testing data by base models (<strong>each base model is trained 5 times, therefore we have to take an average to obtain a matrix of the same shape</strong>) as the input for the stacker and obtain our final predictions.</p>
<p>Maybe it’s better to just show the codes:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ensemble</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_folds, stacker, base_models)</span>:</span></span><br><span class="line">        self.n_folds = n_folds</span><br><span class="line">        self.stacker = stacker</span><br><span class="line">        self.base_models = base_models</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit_predict</span><span class="params">(self, X, y, T)</span>:</span></span><br><span class="line">        X = np.array(X)</span><br><span class="line">        y = np.array(y)</span><br><span class="line">        T = np.array(T)</span><br><span class="line"></span><br><span class="line">        folds = list(KFold(len(y), n_folds=self.n_folds, shuffle=<span class="keyword">True</span>, random_state=<span class="number">2016</span>))</span><br><span class="line"></span><br><span class="line">        S_train = np.zeros((X.shape[<span class="number">0</span>], len(self.base_models)))</span><br><span class="line">        S_test = np.zeros((T.shape[<span class="number">0</span>], len(self.base_models)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, clf <span class="keyword">in</span> enumerate(self.base_models):</span><br><span class="line">            S_test_i = np.zeros((T.shape[<span class="number">0</span>], len(folds)))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> j, (train_idx, test_idx) <span class="keyword">in</span> enumerate(folds):</span><br><span class="line">                X_train = X[train_idx]</span><br><span class="line">                y_train = y[train_idx]</span><br><span class="line">                X_holdout = X[test_idx]</span><br><span class="line">                <span class="comment"># y_holdout = y[test_idx]</span></span><br><span class="line">                clf.fit(X_train, y_train)</span><br><span class="line">                y_pred = clf.predict(X_holdout)[:]</span><br><span class="line">                S_train[test_idx, i] = y_pred</span><br><span class="line">                S_test_i[:, j] = clf.predict(T)[:]</span><br><span class="line"></span><br><span class="line">            S_test[:, i] = S_test_i.mean(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.stacker.fit(S_train, y)</span><br><span class="line">        y_pred = self.stacker.predict(S_test)[:]</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br></pre></td></tr></table></figure>
<p>Prize winners usually have larger and much more complicated ensembles. For beginner, implementing a correct 5-fold stacking is good enough.</p>
<h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="*Pipeline"></a>*Pipeline</h3><p>We can see that the workflow for a Kaggle competition is quite complex, especially for model selection and ensemble. Ideally, we need a highly automated pipeline capable of:</p>
<ul>
<li><strong>Modularized feature transformations</strong>. We only need to write a few lines of codes (or better, rules / DSLs) and the new feature is added to the training set.</li>
<li><strong>Automated grid search</strong>. We only need to set up models and parameter grid, the search will be run and the best parameters will be recorded.</li>
<li><strong>Automated ensemble selection</strong>. Use K best models for training the ensemble as soon as we put another base model into the pool.</li>
</ul>
<p>For beginners, the first one is not very important because the number of features is quite manageable; the third one is not important either because typically we only do several ensembles at the end of the competition. But the second one is good to have because <strong>manually recording the performance and parameters of each model is time-consuming and error-prone</strong>.</p>
<p><a href="https://www.kaggle.com/chenglongchen" target="_blank" rel="noopener">Chenglong Chen</a>, the winner of <a href="https://www.kaggle.com/c/crowdflower-search-relevance" target="_blank" rel="noopener">Crowdflower Search Results Relevance</a>, once released his pipeline on <a href="https://github.com/ChenglongChen/Kaggle_CrowdFlower" target="_blank" rel="noopener">GitHub</a>. It’s very complete and efficient. Yet it’s very hard to understand and extract all his logic to build a general framework. This is something you might want to do when you have plenty of time.</p>
<h2 id="Home-Depot-Search-Relevance"><a href="#Home-Depot-Search-Relevance" class="headerlink" title="Home Depot Search Relevance"></a>Home Depot Search Relevance</h2><p>In this section I will share my solution in <a href="https://www.kaggle.com/c/home-depot-product-search-relevance" target="_blank" rel="noopener">Home Depot Search Relevance Competition</a> and what I learned from top teams after the competition.</p>
<p>The task in this competition is to predict how relevant a result is for a search term on Home Depot website. The relevance is an average score from three human evaluators and ranges between 1 ~ 3. Therefore it’s a regression task. The datasets contains search terms, product titles / descriptions and some attributes like brand, size and color. The metric is <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" target="_blank" rel="noopener">RMSE</a>.</p>
<p>This is much like <a href="https://www.kaggle.com/c/crowdflower-search-relevance" target="_blank" rel="noopener">Crowdflower Search Results Relevance</a>. The difference is that <a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa#Weighted_kappa" target="_blank" rel="noopener">Quadratic Weighted Kappa</a> is used in Crowdflower competition and therefore complicated the final cutoff of regression scores. Also there were no attributes provided in Crowdflower.</p>
<h3 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h3><p>There were several quite good EDAs by the time I joined the competition, especially <a href="https://www.kaggle.com/briantc/home-depot-product-search-relevance/homedepot-first-dataexploreation-k" target="_blank" rel="noopener">this one</a>. I learned that:</p>
<ul>
<li>Many search terms / products appeared several times.</li>
<li>Text similarities are great features.</li>
<li>Many products don’t have attributes features. Would this be a problem?</li>
<li>Product ID seems to have strong predictive power. However the overlap of product ID between the training set and the testing set is not very high. Would this contribute to overfitting?</li>
</ul>
<h3 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h3><p>You can find how I did preprocessing and feature engineering <a href="https://github.com/dnc1994/Kaggle-Playground/blob/master/home-depot/Preprocess.ipynb" target="_blank" rel="noopener">on GitHub</a>. I’ll only give a brief summary here:</p>
<ol>
<li>Use <a href="https://www.kaggle.com/steubk/home-depot-product-search-relevance/fixing-typos" target="_blank" rel="noopener">typo dictionary</a> posted in the forum to correct typos in search terms.</li>
<li>Count attributes. Find those frequent and easily exploited ones.</li>
<li>Join the training set with the testing set. This is important because otherwise you’ll have to do feature transformation twice.</li>
<li>Do <strong><a href="https://en.wikipedia.org/wiki/Stemming" target="_blank" rel="noopener">stemming</a></strong> and <strong><a href="https://en.wikipedia.org/wiki/Text_segmentation#Word_segmentation" target="_blank" rel="noopener">tokenizing</a></strong> for all the text fields. Some <strong>normalization</strong> (with digits and units) and <strong>synonym substitutions</strong> are performed manually.</li>
</ol>
<h3 id="Feature"><a href="#Feature" class="headerlink" title="Feature"></a>Feature</h3><ul>
<li>*Attribute Features<ul>
<li>Whether the product contains a certain attribute (brand, size, color, weight, indoor/outdoor, energy star certified …)</li>
<li>Whether a certain attribute matches with the search term</li>
</ul>
</li>
</ul>
<ul>
<li><p>Meta Features</p>
<ul>
<li>Length of each text field</li>
<li>Whether the product contains attribute fields</li>
<li>Brand (encoded as integers)</li>
<li>Product ID</li>
</ul>
</li>
<li><p>Matching</p>
<ul>
<li>Whether search term appears in product title / description / attributes</li>
<li>Count and ratio of search term’s appearance in product title / description / attributes</li>
<li>*Whether the i-th word of search term appears in product title / description / attributes</li>
</ul>
</li>
<li><p>Text similarities between search term and product title/description/attributes</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bag-of-words_model" target="_blank" rel="noopener">BOW</a> <a href="https://en.wikipedia.org/wiki/Cosine_similarity" target="_blank" rel="noopener">Cosine Similairty</a></li>
<li><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" target="_blank" rel="noopener">TF-IDF</a> Cosine Similarity</li>
<li><a href="https://en.wikipedia.org/wiki/Jaccard_index" target="_blank" rel="noopener">Jaccard Similarity</a></li>
<li>*<a href="https://en.wikipedia.org/wiki/Edit_distance" target="_blank" rel="noopener">Edit Distance</a></li>
<li><a href="https://en.wikipedia.org/wiki/Word2vec" target="_blank" rel="noopener">Word2Vec</a> Distance (I didn’t include this because of its poor performance and slow calculation. Yet it seems that I was using it wrong.)</li>
</ul>
</li>
<li><p><strong><a href="https://en.wikipedia.org/wiki/Latent_semantic_indexing" target="_blank" rel="noopener">Latent Semantic Indexing</a>: By performing <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition" target="_blank" rel="noopener">SVD decomposition</a> to the matrix obtained from BOW/TF-IDF Vectorization, we get a latent representation of different search term / product groups. This enables our model to distinguish between groups and assign different weights to features, therefore solving the issue of dependent data and products lacking some features (to an extent).</strong></p>
</li>
</ul>
<p>Note that features listed above with <code>*</code> are the last batch of features I added. The problem is that the model trained on data that included these features performed worse than the previous ones. At first I thought that the increase in number of features would require re-tuning of model parameters. However, after wasting much CPU time on grid search, I still could not beat the old model. I think it might be the issue of <strong>feature correlation</strong> mentioned above. I actually knew a solution that might work, which is to <strong>combine models trained on different version of features by stacking</strong>. Unfortunately I didn’t have enough time to try it. <strong>As a matter of fact, most of top teams regard the ensemble of models trained with different preprocessing and feature engineering pipelines as a key to success</strong>.</p>
<h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p>At first I was using <code>RandomForestRegressor</code> to build my model. Then I tried <strong>Xgboost</strong> and it turned out to be more than twice as fast as Sklearn. From that on what I do everyday is basically running grid search on my work station while working on features on my laptop.</p>
<p>Dataset in this competition is not trivial to validate. It’s not i.i.d. and many records are dependent. Many times I used better features / parameters only to end with worse LB scores. As repeatedly stated by many accomplished Kagglers, you have to trust your own CV score under such situation. Therefore I decided to use 10-fold instead of 5-fold in cross validation and ignore the LB score in the following attempts.</p>
<h3 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h3><p>My final model is an ensemble consisting of 4 base models:</p>
<ul>
<li><code>RandomForestRegressor</code></li>
<li><code>ExtraTreesRegressor</code></li>
<li><code>GradientBoostingRegressor</code></li>
<li><code>XGBRegressor</code></li>
</ul>
<p>The stacker is also a <code>XGBRegressor</code>.</p>
<p>The problem is that all my base models are highly correlated (with a lowest correlation of 0.9). I thought of including linear regression, SVM regression and <code>XGBRegressor</code> with linear booster into the ensemble, but these models had RMSE scores that are 0.02 higher (this accounts for a gap of hundreds of places on the leaderboard) than the 4 models I finally used. Therefore I decided not to use more models although they would have brought much more diversity.</p>
<p>The good news is that, despite base models being highly correlated, stacking still bumps up my score a lot. <strong>What’s more, my CV score and LB score are in complete sync after I started stacking.</strong></p>
<p>During the last two days of the competition, I did one more thing: <strong>use 20 or so different random seeds to generate the ensemble and take a weighted average of them as the final submission</strong>. This is actually a kind of <strong>bagging</strong>. It makes sense in theory because in stacking I used 80% of the data to train base models in each iteration, whereas 100% of the data is used to train the stacker. Therefore it’s less clean. Making multiple runs with different seeds makes sure that <strong>different 80% of the data are used each time</strong>, thus reducing the risk of information leak. Yet by doing this I only achieved an increase of <code>0.0004</code>, which might be just due to randomness.</p>
<p>After the competition, I found out that my best single model scores <code>0.46378</code> on the private leaderboard, whereas my best stacking ensemble scores <code>0.45849</code>. That was the difference between the 174th place and the 98th place. In other words, feature engineering and model tuning got me into 10%, whereas stacking got me into 5%.</p>
<h3 id="Lessons-Learned"><a href="#Lessons-Learned" class="headerlink" title="Lessons Learned"></a>Lessons Learned</h3><p>There’s much to learn from the solutions shared by top teams:</p>
<ul>
<li><p>There’s a pattern in the product title. For example, whether a product is accompanied by a certain accessory will be indicated by <code>With/Without XXX</code> at the end of the title.</p>
</li>
<li><p>Use external data. For example use <a href="https://wordnet.princeton.edu/" target="_blank" rel="noopener">WordNet</a> or <a href="https://www.kaggle.com/reddit/reddit-comments-may-2015" target="_blank" rel="noopener">Reddit Comments Dataset</a> to train synonyms and <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy" target="_blank" rel="noopener">hypernyms</a>.</p>
</li>
<li><p>Some features based on <strong>letters</strong> instead of <strong>words</strong>. At first I was rather confused by this. But it makes perfect sense if you consider it. For example, the team that won the 3rd place took the number of letters matched into consideration when computing text similarity. They argued that <strong>longer words are more specific and thus more likely to be assigned high relevance scores by human</strong>. They also used char-by-char sequence comparison (<code>difflib.SequenceMatcher</code>) to measure <strong>visual similarity</strong>, which they claimed to be important for human.</p>
</li>
<li><p>POS-tag words and find <strong><a href="https://en.wikipedia.org/wiki/Head_(linguistics)" target="_blank" rel="noopener">head</a></strong> in phrases and use them when computing various distance metrics.</p>
</li>
<li><p>Extract top-ranking trigrams from the TF-IDF of product title / description field and compute the ratio of word from search terms that appear in these trigrams. Vice versa. This is like computing latent indexes from another point of view.</p>
</li>
<li><p>Some novel distance metrics like <a href="http://jmlr.org/proceedings/papers/v37/kusnerb15.pdf" target="_blank" rel="noopener">Word Movers Distance</a></p>
</li>
<li><p>Apart from SVD, some used <a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization" target="_blank" rel="noopener">NMF</a>.</p>
</li>
<li><p>Generate <strong>pairwise polynomial interactions</strong> between top-ranking features.</p>
</li>
<li><p><strong>For CV, construct splits in which product IDs do not overlap between training set and testing set, and splits in which IDs do. Then we can use these with corresponding ratio to approximate the impact of public/private LB split in our local CV.</strong></p>
</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><h3 id="Takeaways"><a href="#Takeaways" class="headerlink" title="Takeaways"></a>Takeaways</h3><ol>
<li>It was a good call to <strong>start doing ensembles early in the competition</strong>. As it turned out, I was still playing with features during the very last days.</li>
<li>It’s of high priority that I build a pipeline capable of automatic model training and recording best parameters.</li>
<li><strong>Features matter the most!</strong> I didn’t spend enough time on features in this competition.</li>
<li>If possible, spend some time to manually inspect raw data for patterns.</li>
</ol>
<h3 id="Issues-Raised"><a href="#Issues-Raised" class="headerlink" title="Issues Raised"></a>Issues Raised</h3><p>Several issues I encountered in this competitions are of high research values.</p>
<ol>
<li>How to do reliable CV with dependent data.</li>
<li>How to quantify <strong>the trade-off between diversity and accuracy</strong> in ensemble learning.</li>
<li>How to deal with feature interaction which harms the model’s performance. And <strong>how to determine whether new features are effective in such situations</strong>.</li>
</ol>
<h3 id="Beginner-Tips"><a href="#Beginner-Tips" class="headerlink" title="Beginner Tips"></a>Beginner Tips</h3><ol>
<li>Choose a competition you’re interested in. <strong>It would be better if you’ve already have some insights about the problem domain.</strong></li>
<li>Following my approach or somebody else’s, start exploring, understanding and modeling data.</li>
<li>Learn from forum and scripts. See how others interpret data and construct features.</li>
<li><strong>Find winner interviews / blog posts of previous competitions. They’re extremely helpful, especially if from competitions that share some similarities with that one you’re working on.</strong></li>
<li>Start doing ensemble after you have reached a pretty good score (e.g. 10% ~ 20%) or you feel that there isn’t much room for new features (which, sadly, always turns out to be false).</li>
<li>If you think you may have a chance to win the prize, try teaming up!</li>
<li><strong>Don’t give up until the end of the competition. At least try something new every day.</strong></li>
<li>Learn from the sharings of top teams after the competition. Reflect on your approaches. <strong>If possible, spend some time verifying what you learn.</strong></li>
<li>Get some rest!</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiPxZHewLbMAhVKv5QKHb3PCGwQFggcMAA&amp;url=http%3A%2F%2Fwww.ke.tu-darmstadt.de%2Flehre%2Farbeiten%2Fstudien%2F2015%2FDong_Ying.pdf&amp;usg=AFQjCNE9o2BcEkqdnu_-lQ3EFD3eRAFWiw&amp;sig2=oiU8TCEH57EYF9v9l6Scrw&amp;bvm=bv.121070826,d.dGo" target="_blank" rel="noopener">Beating Kaggle the Easy Way - Dong Ying</a></li>
<li><a href="https://github.com/ChenglongChen/Kaggle_CrowdFlower/blob/master/BlogPost/BlogPost.md" target="_blank" rel="noopener">Search Results Relevance Winner’s Interview: 1st place, Chenglong Chen</a></li>
<li><a href="http://rstudio-pubs-static.s3.amazonaws.com/158725_5d2f977f4004490e9b095c0ef9357c6b.html" target="_blank" rel="noopener">(Chinese) Solution for Prudential Life Insurance Assessment - Nutastray</a></li>
</ol>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Buy me an Asahi beer :)</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/uploads/donate-alipay.jpg" alt="Linghao Zhang Alipay"/>
        <p>Alipay</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/04/rank-10-percent-in-first-kaggle-competition/" rel="next" title="如何在 Kaggle 首战中进入前 10%">
                <i class="fa fa-chevron-left"></i> 如何在 Kaggle 首战中进入前 10%
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/01/gradschool-application-diy-demystified/" rel="prev" title="DIY 留学申请全攻略">
                DIY 留学申请全攻略 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/asuka.png"
                alt="Linghao Zhang" />
            
              <p class="site-author-name" itemprop="name">Linghao Zhang</p>
              <p class="site-description motion-element" itemprop="description">Creating and Distilling Knowledge</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:hi@linghao.io" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/dnc1994" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.linkedin.com/in/linghaozh" target="_blank" title="LinkedIn">
                      
                        <i class="fa fa-fw fa-linkedin"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://t.me/linghao" target="_blank" title="Telegram">
                      
                        <i class="fa fa-fw fa-telegram"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://twitter.com/instante_42" target="_blank" title="Twitter">
                      
                        <i class="fa fa-fw fa-twitter"></i></a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.instagram.com/instante_42" target="_blank" title="Instagram">
                      
                        <i class="fa fa-fw fa-instagram"></i></a>
                  </span>
                
            </div>
          

          
          
            <div class="cc-license motion-element" itemprop="license">
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
                <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
              </a>
            </div>
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://shud.in/about/" title="Shu Ding" target="_blank">Shu Ding</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://dsdshcym.github.io/blog/" title="Yiming Chen" target="_blank">Yiming Chen</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://taineleau.me/" title="Danlu Chen" target="_blank">Danlu Chen</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://endle.github.io/" title="Zhenbo Li" target="_blank">Zhenbo Li</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#General-Approach"><span class="nav-number">2.</span> <span class="nav-text">General Approach</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Exploration"><span class="nav-number">2.1.</span> <span class="nav-text">Data Exploration</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Visualization"><span class="nav-number">2.1.1.</span> <span class="nav-text">Visualization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Statistical-Tests"><span class="nav-number">2.1.2.</span> <span class="nav-text">Statistical Tests</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Preprocessing"><span class="nav-number">2.2.</span> <span class="nav-text">Data Preprocessing</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Outlier"><span class="nav-number">2.2.1.</span> <span class="nav-text">Outlier</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dummy-Variables"><span class="nav-number">2.2.2.</span> <span class="nav-text">Dummy Variables</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Engineering"><span class="nav-number">2.3.</span> <span class="nav-text">Feature Engineering</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Feature-Selection"><span class="nav-number">2.3.1.</span> <span class="nav-text">Feature Selection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Feature-Encoding"><span class="nav-number">2.3.2.</span> <span class="nav-text">Feature Encoding</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-Selection"><span class="nav-number">2.4.</span> <span class="nav-text">Model Selection</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Model-Training"><span class="nav-number">2.4.1.</span> <span class="nav-text">Model Training</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Cross-Validation"><span class="nav-number">2.4.2.</span> <span class="nav-text">Cross Validation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Ensemble-Generation"><span class="nav-number">2.5.</span> <span class="nav-text">Ensemble Generation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Stacking"><span class="nav-number">2.5.1.</span> <span class="nav-text">Stacking</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pipeline"><span class="nav-number">2.6.</span> <span class="nav-text">*Pipeline</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Home-Depot-Search-Relevance"><span class="nav-number">3.</span> <span class="nav-text">Home Depot Search Relevance</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#EDA"><span class="nav-number">3.1.</span> <span class="nav-text">EDA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Preprocessing"><span class="nav-number">3.2.</span> <span class="nav-text">Preprocessing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature"><span class="nav-number">3.3.</span> <span class="nav-text">Feature</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model"><span class="nav-number">3.4.</span> <span class="nav-text">Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Ensemble"><span class="nav-number">3.5.</span> <span class="nav-text">Ensemble</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lessons-Learned"><span class="nav-number">3.6.</span> <span class="nav-text">Lessons Learned</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary"><span class="nav-number">4.</span> <span class="nav-text">Summary</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Takeaways"><span class="nav-number">4.1.</span> <span class="nav-text">Takeaways</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Issues-Raised"><span class="nav-number">4.2.</span> <span class="nav-text">Issues Raised</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Beginner-Tips"><span class="nav-number">4.3.</span> <span class="nav-text">Beginner Tips</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2015 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Linghao Zhang</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://wille-lhz.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/';
          this.page.identifier = '2016/05/rank-10-percent-in-first-kaggle-competition-en/';
          this.page.title = 'How to Rank 10% in Your First Kaggle Competition';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://wille-lhz.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  

  

  

</body>
</html>
